{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this notebook, we preprocess the text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "\n",
    "from covid.config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config('../config.json')\n",
    "\n",
    "bucket = 'mleila-covid'\n",
    "prefix = 'models/'\n",
    "region_name = boto3.Session().region_name\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = config.SM_ROLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download file\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(bucket).download_file('raw/covid/articles.txt', 'articles.txt')\n",
    "\n",
    "# read file\n",
    "with open('articles.txt', 'r') as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# first time, download stopwords\n",
    "#nltk.download('stopwords');\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "clean_data = [' '.join([w for w in sentence.split() if w not in stop_words]) for sentence in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merch vendors are selling novelty shirts that have to do with the new coronavirus or COVID-19. The respiratory infection has already driven face mask vendors to raise prices, and now shirt sellers see an opportunity for profit. \n",
      "\n",
      "Merch vendors selling novelty shirts new coronavirus COVID-19. The respiratory infection already driven face mask vendors raise prices, shirt sellers see opportunity profit.\n"
     ]
    }
   ],
   "source": [
    "print(data[0])\n",
    "print(clean_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowercase everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = [sentence.lower() for sentence in clean_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text: str):\n",
    "    \"\"\"\n",
    "    Remove punctuations using regex rules.\n",
    "    \"\"\"\n",
    "    # remove tbc dots\n",
    "    text = re.sub('â€¦', '', text)\n",
    "    # remove urls\n",
    "    text = re.sub('http\\S+', '', text, flags=re.MULTILINE)\n",
    "    # remove periods and commas, etc.\n",
    "    text = (text\n",
    "            .replace('.', '')\n",
    "            .replace(',', '')\n",
    "            .replace(':', '')\n",
    "            .replace('#', '')\n",
    "            .replace('\"', '')\n",
    "            .replace(\"'\", '')\n",
    "            .replace(\")\", '')\n",
    "            .replace(\"(\", '')\n",
    "           ) \n",
    "    # remove single character words\n",
    "    text = ' '.join([word for word in text.split() if len(word)>1])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = [remove_punct(sentence) for sentence in clean_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple google taking measures prevent spread coronavirus misinformation apps according report cnbc apple one rejecting coronavirus-related mobile apps government official health organizati',\n",
       " 'timeline coronavirus covid-19 canada ctv news husband toronto woman returned iran ontarios sixth covid-19 case cp24 torontos breaking news husband ontarios fifth covid-19 patient also tests positive virus ctv news husband cov']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data[30:32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Data back to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clean_articles.txt', 'w') as f:\n",
    "    for line in data:\n",
    "        f.writelines(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.Bucket(bucket).upload_file('clean_articles.txt', 'processed/covid/articles.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid",
   "language": "python",
   "name": "covid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
